import 'package:flutter/material.dart';
import 'package:google_generative_ai/google_generative_ai.dart';
import 'package:flutter_markdown/flutter_markdown.dart';
import 'services/rag_service.dart';
import 'dart:async';
import 'dart:io';
import 'package:http/http.dart' as http;
import 'dart:convert';
import 'package:audioplayers/audioplayers.dart';
import 'package:path_provider/path_provider.dart';

class VoiceChatPage extends StatefulWidget {
  final String? initialTopic;
  
  const VoiceChatPage({super.key, this.initialTopic});

  @override
  State<VoiceChatPage> createState() => _VoiceChatPageState();
}

class _VoiceChatPageState extends State<VoiceChatPage> with TickerProviderStateMixin {
  final List<Map<String, String>> _messages = [];
  bool _isListening = false;
  bool _isSpeaking = false;
  bool _isProcessing = false;
  final RAGService _ragService = RAGService();
  List<KnowledgeChunk> _lastRetrievedInfo = [];
  
  // Audio player for device playback
  final AudioPlayer _audioPlayer = AudioPlayer();
  
  // Animation controllers
  late AnimationController _waveController;
  late AnimationController _pulseController;
  late Animation<double> _waveAnimation;
  late Animation<double> _pulseAnimation;

  // Azure service configuration
  final String azureServiceUrl = 'http://10.126.240.141:5000'; // Your computer's IP address
  
  // Initialize Google AI model
  final generationConfig = GenerationConfig();
  final systemInstruction = Content.system('''
    You are a first aid medical assistant chatbot named "Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¥Ø³Ø¹Ø§ÙØ§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ©" (First Aid Assistant), inspired by the warm and welcoming spirit of Morocco. Always respond in clear, formal Arabic (fusha), using an intuitive, friendly, and empathetic tone that reflects the hospitality and calm demeanor of an Ifrane local. Your goal is to provide accurate, step-by-step first aid guidance based on trusted medical information retrieved from an Arabic knowledge base, making users feel supported as if guided by a kind neighbor from Ifrane's serene mountain community.

    Follow these guidelines:
    1. **Tone and Personality**: Embody the warmth and tranquility of Morocco. Be approachable, reassuring, and community-oriented, like a trusted friend from a small town. Use phrases that evoke care, e.g., "Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ø£Ø³Ø§Ø¹Ø¯Ùƒ Ø¨ÙƒÙ„ Ù‡Ø¯ÙˆØ¡ØŒ ÙƒÙ…Ø§ Ù„Ùˆ ÙƒÙ†Ø§ Ù†ØªØ­Ø¯Ø« ÙÙŠ Ø¸Ù„Ø§Ù„ Ø£Ø´Ø¬Ø§Ø± Ø§Ù„Ø£Ø±Ø² Ø¨Ø¥ÙØ±Ø§Ù†." Explain first aid steps simply, avoiding complex medical terms unless clarified (e.g., "Ø§Ù„Ù†Ø²ÙŠÙ" explained as "Ø®Ø±ÙˆØ¬ Ø§Ù„Ø¯Ù…"). Show empathy, e.g., "Ø£Ø¹Ù„Ù… Ø£Ù† Ù‡Ø°Ø§ Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…Ù‚Ù„Ù‚Ù‹Ø§ØŒ Ù„ÙƒÙ† Ø¯Ø¹Ù†Ø§ Ù†ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡ Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©."
    2. **Response Structure**: Provide answers in numbered lists or clear paragraphs for readability. Offer practical, actionable steps, e.g., "1. Ø§ØºØ³Ù„ Ø§Ù„Ø¬Ø±Ø­ Ø¨Ø§Ù„Ù…Ø§Ø¡ Ø§Ù„Ù†Ø¸ÙŠÙ Ù„Ù…Ø¯Ø© 5 Ø¯Ù‚Ø§Ø¦Ù‚." If the query is vague, ask politely for clarification, e.g., "Ù…Ù† ÙØ¶Ù„ÙƒØŒ Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ÙˆØµÙ Ø§Ù„Ø¥ØµØ§Ø¨Ø© Ø¨Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØµÙŠÙ„ Ù„Ø£Ø³Ø§Ø¹Ø¯Ùƒ Ø¨Ø£ÙØ¶Ù„ Ø·Ø±ÙŠÙ‚Ø©ØŸ"
    3. **Safety and Disclaimers**: Always end responses with: "Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù„Ù„Ø£ØºØ±Ø§Ø¶ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙÙ‚Ø·. Ø§Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø·Ø¨ÙŠØ© Ø§Ù„Ù…Ù‡Ù†ÙŠØ© ÙÙˆØ±Ù‹Ø§ Ø£Ùˆ Ø§ØªØµÙ„ Ø¨Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø­Ø§Ù„Ø© Ø®Ø·ÙŠØ±Ø©."
    4. **Use Retrieved Data**: Incorporate relevant information from the Arabic knowledge base (via RAG) to ensure accuracy. If no relevant data is retrieved, use general first aid knowledge cautiously and emphasize professional help.
    5. **Cultural Sensitivity**: Reflect Ifrane's inclusive and hospitable culture. Use polite, formal Arabic (fusha) phrases (e.g., "Ù…Ù† ÙØ¶Ù„Ùƒ", "Ø¨Ø§Ø±Ùƒ Ø§Ù„Ù„Ù‡ ÙÙŠÙƒ").
    6. **Edge Cases**: If the query is unrelated to first aid, respond with Ifrane-inspired warmth but redirect, e.g., "ÙƒÙ…Ø§ ÙÙŠ Ø¥ÙØ±Ø§Ù†ØŒ Ù†Ø­Ø¨ Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ÙÙŠØ¯Ø©! Ù‡Ù„ Ù„Ø¯ÙŠÙƒ Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø¥Ø³Ø¹Ø§ÙØ§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ©ØŒ Ù…Ø«Ù„ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø­Ø±ÙˆÙ‚ØŸ"
    7. **Use Retrieved Data**: Incorporate relevant information from the Arabic knowledge base (via RAG) to ensure accuracy. If no relevant data is retrieved, use general first aid knowledge cautiously and emphasize professional help.
    8. **Response size and language**: Keep responses VERY concise (maximum 3-4 sentences or 3-4 numbered steps). Use simple, clear language. Always address the user as "Ù…Ø±ÙŠØ¶" (male patient) in Arabic. Avoid long explanations. THIS IS CRITICAL FOR VOICE INTERACTIONS - keep responses short and clear.Don't use stars or bold text,just plain text response.
    

    Example Response:
    Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„Ùƒ Ø­ÙˆÙ„ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø­Ø±ÙˆÙ‚ Ø§Ù„Ø¨Ø³ÙŠØ·Ø©:
    1. Ø¶Ø¹ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…ØµØ§Ø¨Ø© ØªØ­Øª Ù…Ø§Ø¡ Ø¨Ø§Ø±Ø¯ Ù„Ù…Ø¯Ø© 10 Ø¯Ù‚Ø§Ø¦Ù‚.
    2. Ø¬ÙÙ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø¨Ù„Ø·Ù ÙˆØºØ·Ù‡Ø§ Ø¨Ø¶Ù…Ø§Ø¯Ø© Ù…Ø¹Ù‚Ù…Ø©.
    3. Ù„Ø§ ØªØ¶Ø¹ Ø§Ù„Ø«Ù„Ø¬ Ø£Ùˆ Ø§Ù„Ø²Ø¨Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±Ù‚.
    Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù„Ù„Ø£ØºØ±Ø§Ø¶ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙÙ‚Ø·. Ø§Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø·Ø¨ÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø­Ø±Ù‚ ÙƒØ¨ÙŠØ±Ø§Ù‹.

    Always stay within the scope of first aid, prioritize user safety, and reflect the caring spirit of Ifrane's community.
  ''');

  late final GenerativeModel model;
  late final ChatSession chat;

  @override
  void initState() {
    super.initState();
    _initializeServices();
    _initializeAnimations();
  }

  void _initializeAnimations() {
    // Wave animation for listening state
    _waveController = AnimationController(
      duration: const Duration(milliseconds: 1500),
      vsync: this,
    );
    _waveAnimation = Tween<double>(begin: 0.0, end: 1.0).animate(
      CurvedAnimation(parent: _waveController, curve: Curves.easeInOut),
    );

    // Pulse animation for speaking state
    _pulseController = AnimationController(
      duration: const Duration(milliseconds: 1000),
      vsync: this,
    );
    _pulseAnimation = Tween<double>(begin: 0.8, end: 1.2).animate(
      CurvedAnimation(parent: _pulseController, curve: Curves.easeInOut),
    );
  }

  Future<void> _initializeServices() async {
    // Initialize RAG service first
    await _ragService.initialize();
    
    // Initialize the model and chat session
    model = GenerativeModel(
      model: 'gemini-2.5-flash',
      apiKey: 'AIzaSyAKXgi70t9Huc9UG5rTspddYRWxC70Ne6s',
      generationConfig: generationConfig,
      systemInstruction: systemInstruction,
    );
    chat = model.startChat();
    
    // If there's an initial topic, send it automatically
    if (widget.initialTopic != null) {
      WidgetsBinding.instance.addPostFrameCallback((_) {
        _startVoiceInteraction('Ø£Ø±ÙŠØ¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† ${widget.initialTopic}');
      });
    }
  }

  Future<String?> _speechToText() async {
    try {
      print('ğŸ¤ Calling STT endpoint: $azureServiceUrl/speech-to-text');
      
      final response = await http.post(
        Uri.parse('$azureServiceUrl/speech-to-text'),
        headers: {'Content-Type': 'application/json'},
        body: jsonEncode({'language': 'ar-MA'}),
      ).timeout(Duration(seconds: 30));
      
      print('STT Response status: ${response.statusCode}');
      
      if (response.statusCode == 200) {
        final data = jsonDecode(response.body);
        print('STT Response data: $data');
        
        if (data['success'] == true) {
          return data['text'];
        } else {
          print('STT failed: ${data['error']}');
          _showSnackBar('ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª: ${data['error']}');
        }
      } else {
        print('STT HTTP error: ${response.statusCode} - ${response.body}');
        _showSnackBar('Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø¯Ù…Ø© Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª');
      }
    } catch (e) {
      print('STT Error: $e');
      _showSnackBar('Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª: $e');
    }
    return null;
  }

  Future<bool> _textToSpeech(String text) async {
    try {
      print('ğŸ”Š Calling TTS endpoint: $azureServiceUrl/text-to-speech-file');
      print('TTS Text: ${text.substring(0, text.length > 50 ? 50 : text.length)}...');
      
      final response = await http.post(
        Uri.parse('$azureServiceUrl/text-to-speech-file'),
        headers: {'Content-Type': 'application/json'},
        body: jsonEncode({
          'text': text,
          'voice': 'ar-MA-MounaNeural',
        }),
      ).timeout(Duration(seconds: 30));
      
      print('TTS Response status: ${response.statusCode}');
      print('TTS Response size: ${response.bodyBytes.length} bytes');
      
      if (response.statusCode == 200) {
        if (response.bodyBytes.length > 1000) {
          // Save audio file temporarily and play it
          return await _playAudioFromBytes(response.bodyBytes);
        } else {
          print('TTS response too small, likely an error');
          _showSnackBar('Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØµÙˆØªÙŠØ© ØµØºÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ØŒ Ø±Ø¨Ù…Ø§ Ù‡Ù†Ø§Ùƒ Ø®Ø·Ø£');
          return false;
        }
      } else {
        print('TTS HTTP error: ${response.statusCode} - ${response.body}');
        _showSnackBar('Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª');
        return false;
      }
    } catch (e) {
      print('TTS Error: $e');
      _showSnackBar('Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙˆØª: $e');
      return false;
    }
  }

  Future<bool> _playAudioFromBytes(List<int> audioBytes) async {
    try {
      print('Audio received: ${audioBytes.length} bytes');
      
      // Get temporary directory
      final tempDir = await getTemporaryDirectory();
      final tempFile = File('${tempDir.path}/temp_audio_${DateTime.now().millisecondsSinceEpoch}.wav');
      
      // Write audio bytes to temporary file
      await tempFile.writeAsBytes(audioBytes);
      print('Audio saved to: ${tempFile.path}');
      
      // Play audio on device
      await _audioPlayer.play(DeviceFileSource(tempFile.path));
      
      // Wait for audio to complete
      await _audioPlayer.onPlayerComplete.first;
      
      // Clean up temporary file
      try {
        await tempFile.delete();
      } catch (e) {
        print('Could not delete temp file: $e');
      }
      
      return true;
    } catch (e) {
      print('Audio playback error: $e');
      return false;
    }
  }

  Future<void> _startVoiceInteraction([String? initialMessage]) async {
    if (_isListening || _isSpeaking || _isProcessing) return;

    String? userMessage = initialMessage;
    
    if (userMessage == null) {
      // Start listening for user input
      setState(() {
        _isListening = true;
      });
      _waveController.repeat(reverse: true);

      userMessage = await _speechToText();
      
      _waveController.stop();
      setState(() {
        _isListening = false;
      });
    }

    if (userMessage == null || userMessage.trim().isEmpty) {
      _showSnackBar('Ù„Ù… ÙŠØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø£ÙŠ ØµÙˆØª. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.');
      return;
    }

    // Add user message to chat
    setState(() {
      _messages.add({'sender': 'user', 'text': userMessage!});
      _isProcessing = true;
    });

    try {
      // Retrieve relevant information from knowledge base
      final relevantInfo = _ragService.retrieveRelevantInfo(userMessage);
      _lastRetrievedInfo = relevantInfo;
      
      // Construct enhanced prompt with retrieved information
      String enhancedPrompt = userMessage;
      if (relevantInfo.isNotEmpty) {
        enhancedPrompt += '\n\nÙ…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø±Ø¬Ø¹ÙŠØ© Ù…Ù† Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø³Ø¹Ø§ÙØ§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ©:\n';
        for (final chunk in relevantInfo) {
          enhancedPrompt += '\n--- ${chunk.title} ---\n${chunk.content}\n';
        }
        enhancedPrompt += '\nÙŠØ±Ø¬Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ© Ù„ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙØµÙ„Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø¯Ø§Ø±Ø¬Ø© Ø§Ù„Ù…ØºØ±Ø¨ÙŠØ©.';
      }

      final response = await chat.sendMessage(Content.text(enhancedPrompt));
      final botResponse = response.text ?? 'Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù„Ù… Ø£Ø³ØªØ·Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ.';
      
      setState(() {
        _messages.add({'sender': 'bot', 'text': botResponse});
        _isProcessing = false;
        _isSpeaking = true;
      });

      // Start speaking animation
      _pulseController.repeat(reverse: true);
      
      // Speak the response
      await _textToSpeech(botResponse);
      
      // Stop speaking animation
      _pulseController.stop();
      setState(() {
        _isSpeaking = false;
      });

    } catch (e) {
      setState(() {
        _messages.add({'sender': 'bot', 'text': 'Ø­Ø¯Ø« Ø®Ø·Ø£: $e'});
        _isProcessing = false;
        _isSpeaking = false;
      });
      _pulseController.stop();
    }
  }

  void _showSnackBar(String message) {
    ScaffoldMessenger.of(context).showSnackBar(
      SnackBar(
        content: Text(
          message,
          style: const TextStyle(fontFamily: 'Amiri'),
          textDirection: TextDirection.rtl,
        ),
        backgroundColor: const Color(0xFF4A7043),
      ),
    );
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: const Text(
          'Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„ØµÙˆØªÙŠØ© - Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¥Ø³Ø¹Ø§ÙØ§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ©',
          style: TextStyle(fontFamily: 'Amiri', color: Colors.white),
        ),
        backgroundColor: const Color(0xFF4A7043),
        centerTitle: true,
        actions: [
          IconButton(
            icon: const Icon(Icons.refresh, color: Colors.white),
            onPressed: () {
              setState(() {
                _messages.clear();
                _lastRetrievedInfo.clear();
              });
            },
          ),
        ],
      ),
      body: Column(
        children: [
          // RAG status indicator
          if (_lastRetrievedInfo.isNotEmpty)
            Container(
              width: double.infinity,
              padding: const EdgeInsets.symmetric(horizontal: 8.0, vertical: 4.0),
              color: const Color(0xFFE6F0EA),
              child: Row(
                children: [
                  const Icon(Icons.library_books, size: 16, color: Color(0xFF4A7043)),
                  const SizedBox(width: 4),
                  Text(
                    'ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… ${_lastRetrievedInfo.length} Ù…Ø±Ø§Ø¬Ø¹ Ù…Ù† Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø³Ø¹Ø§ÙØ§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ©',
                    style: const TextStyle(
                      fontSize: 12,
                      color: Color(0xFF4A7043),
                      fontFamily: 'Amiri',
                    ),
                  ),
                ],
              ),
            ),
          
          // Messages list
          Expanded(
            child: ListView.builder(
              padding: const EdgeInsets.all(8.0),
              itemCount: _messages.length + (_isProcessing ? 1 : 0),
              itemBuilder: (context, index) {
                if (_isProcessing && index == _messages.length) {
                  return const Align(
                    alignment: Alignment.centerRight,
                    child: Padding(
                      padding: EdgeInsets.all(8.0),
                      child: CircularProgressIndicator(
                        valueColor: AlwaysStoppedAnimation<Color>(Color(0xFF4A7043)),
                      ),
                    ),
                  );
                }
                final message = _messages[index];
                final isUser = message['sender'] == 'user';
                return Align(
                  alignment: isUser ? Alignment.centerLeft : Alignment.centerRight,
                  child: Container(
                    margin: const EdgeInsets.symmetric(vertical: 4.0, horizontal: 8.0),
                    padding: const EdgeInsets.all(12.0),
                    decoration: BoxDecoration(
                      color: isUser ? Colors.grey[200] : const Color(0xFFE6F0EA),
                      borderRadius: BorderRadius.circular(12.0),
                    ),
                    child: isUser 
                      ? Text(
                          message['text']!,
                          style: const TextStyle(
                            fontFamily: 'Amiri',
                            fontSize: 16.0,
                            color: Colors.black87,
                          ),
                          textAlign: TextAlign.left,
                          textDirection: TextDirection.ltr,
                        )
                      : Directionality(
                          textDirection: TextDirection.rtl,
                          child: MarkdownBody(
                            data: message['text']!,
                            styleSheet: MarkdownStyleSheet(
                              p: const TextStyle(
                                fontFamily: 'Amiri',
                                fontSize: 16.0,
                                color: Colors.black87,
                                height: 1.4,
                              ),
                              strong: const TextStyle(
                                fontFamily: 'Amiri',
                                fontSize: 16.0,
                                color: Colors.black87,
                                fontWeight: FontWeight.bold,
                              ),
                              listBullet: const TextStyle(
                                fontFamily: 'Amiri',
                                fontSize: 16.0,
                                color: Colors.black87,
                              ),
                            ),
                          ),
                        ),
                  ),
                );
              },
            ),
          ),
          
          // Voice interaction controls
          Container(
            padding: const EdgeInsets.all(16.0),
            decoration: const BoxDecoration(
              color: Color(0xFFF5F5F5),
              borderRadius: BorderRadius.only(
                topLeft: Radius.circular(20),
                topRight: Radius.circular(20),
              ),
            ),
            child: Column(
              children: [
                // Status text
                Text(
                  _getStatusText(),
                  style: const TextStyle(
                    fontFamily: 'Amiri',
                    fontSize: 18.0,
                    color: Color(0xFF4A7043),
                    fontWeight: FontWeight.bold,
                  ),
                  textAlign: TextAlign.center,
                  textDirection: TextDirection.rtl,
                ),
                const SizedBox(height: 20),
                
                // Voice button with animation
                GestureDetector(
                  onTap: _isListening || _isSpeaking || _isProcessing 
                    ? null 
                    : _startVoiceInteraction,
                  child: AnimatedBuilder(
                    animation: _isListening ? _waveAnimation : _pulseAnimation,
                    builder: (context, child) {
                      return Transform.scale(
                        scale: _isListening ? (1.0 + _waveAnimation.value * 0.1) 
                              : _isSpeaking ? _pulseAnimation.value 
                              : 1.0,
                        child: Container(
                          width: 120,
                          height: 120,
                          decoration: BoxDecoration(
                            color: _getButtonColor(),
                            shape: BoxShape.circle,
                            boxShadow: [
                              BoxShadow(
                                color: _getButtonColor().withOpacity(0.3),
                                spreadRadius: _isListening ? 10 : 5,
                                blurRadius: _isListening ? 20 : 10,
                                offset: const Offset(0, 3),
                              ),
                            ],
                          ),
                          child: Icon(
                            _getButtonIcon(),
                            size: 50,
                            color: Colors.white,
                          ),
                        ),
                      );
                    },
                  ),
                ),
                const SizedBox(height: 16),
                
                // Instruction text
                Text(
                  _getInstructionText(),
                  style: const TextStyle(
                    fontFamily: 'Amiri',
                    fontSize: 14.0,
                    color: Colors.grey,
                  ),
                  textAlign: TextAlign.center,
                  textDirection: TextDirection.rtl,
                ),
              ],
            ),
          ),
        ],
      ),
    );
  }

  String _getStatusText() {
    if (_isListening) return 'Ø£Ø³ØªÙ…Ø¹ Ø¥Ù„ÙŠÙƒ...';
    if (_isSpeaking) return 'Ø£ØªØ­Ø¯Ø« Ù…Ø¹Ùƒ...';
    if (_isProcessing) return 'Ø£ÙÙƒØ± ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©...';
    return 'Ø§Ø¶ØºØ· Ù„Ù„ØªØ­Ø¯Ø« Ù…Ø¹ÙŠ';
  }

  Color _getButtonColor() {
    if (_isListening) return Colors.red;
    if (_isSpeaking) return Colors.blue;
    if (_isProcessing) return Colors.orange;
    return const Color(0xFF4A7043);
  }

  IconData _getButtonIcon() {
    if (_isListening) return Icons.mic;
    if (_isSpeaking) return Icons.volume_up;
    if (_isProcessing) return Icons.hourglass_empty;
    return Icons.mic_none;
  }

  String _getInstructionText() {
    if (_isListening) return 'ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù† Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©...';
    if (_isSpeaking) return 'Ø£Ø³ØªÙ…Ø¹ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©...';
    if (_isProcessing) return 'Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ...';
    return 'Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† ÙˆØªØ­Ø¯Ø« Ø¹Ù† Ù…Ø´ÙƒÙ„ØªÙƒ Ø§Ù„Ø·Ø¨ÙŠØ©';
  }

  @override
  void dispose() {
    _waveController.dispose();
    _pulseController.dispose();
    _audioPlayer.dispose();
    super.dispose();
  }
}
